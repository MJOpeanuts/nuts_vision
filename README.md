# nuts_vision

Automated electronic circuit board analyser â€” upload a photo of a PCB, detect every component with YOLOv8, crop each one individually, and browse the results through a Streamlit web interface.

## What the application does

1. **Upload** one or more PCB photos via the web interface.
2. **Detect** â€” a YOLOv8 model identifies and classifies every component on the board (16 classes).
3. **Crop** â€” each detected component is saved as a separate image.
4. **Browse** â€” every analysis is stored as a *job* (its own folder) that you can review in the **Job Viewer** page.
5. **Log** *(optional)* â€” all results can be stored in a PostgreSQL database for later querying and statistics.

### Detectable component classes

IC, LED, Battery, Buzzer, Capacitor, Clock, Connector, Diode, Display, Fuse, Inductor, Potentiometer, Relay, Resistor, Switch, Transistor.

---

## Project structure

```
nuts_vision/
â”œâ”€â”€ app.py                  # Streamlit web interface (main entry point)
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ data.yaml               # YOLO dataset configuration
â”œâ”€â”€ .env.example            # Example environment variables
â”œâ”€â”€ docker-compose.yml      # PostgreSQL container (optional)
â”œâ”€â”€ start_web.sh / .bat     # Convenience launchers
â”œâ”€â”€ setup.py                # Project setup helper
â”œâ”€â”€ check_dependencies.py   # Dependency checker
â”œâ”€â”€ example.py              # Python usage examples
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ YOLO_MODEL.md           # YOLO model details, training and replacement
â”œâ”€â”€ README.roboflow.txt     # Dataset attribution
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ pipeline.py         # Full detect + crop pipeline
â”‚   â”œâ”€â”€ detect.py           # Component detector (YOLOv8 wrapper)
â”‚   â”œâ”€â”€ crop.py             # Component cropper
â”‚   â”œâ”€â”€ train.py            # Model training script
â”‚   â”œâ”€â”€ visualize.py        # Visualization utilities
â”‚   â””â”€â”€ database.py         # PostgreSQL logging (optional)
â””â”€â”€ database/
    â””â”€â”€ init.sql            # Database schema
```

### Job output structure

Each processed image produces a job folder:

```
jobs/
  <image_name>_<YYYYMMDD>_<HHMMSS>/
    input.<ext>     â€” original photo
    result.jpg      â€” annotated photo with bounding boxes
    crops/          â€” one cropped image per detected component
    metadata.json   â€” detection data (class, confidence, bbox, crop filename)
```

---

## Installation

**Requirements:** Python 3.8+, Docker (optional, for the database).

```bash
# Install Python dependencies
pip install -r requirements.txt
```

---

## Running the web interface

```bash
# Quickest way (handles venv + .env automatically)
bash start_web.sh          # Linux / macOS
start_web.bat              # Windows

# Or launch directly
streamlit run app.py
```

Open your browser at **http://localhost:8501**.

### Web interface pages

| Page | Description |
|------|-------------|
| ğŸ  Home | Overview and quick statistics |
| ğŸ“¤ Upload & Process | Upload PCB images and run the detection pipeline |
| ğŸ” Job Viewer | Browse per-job results: input photo, annotated result, crops, metadata |
| ğŸ—„ï¸ Database Viewer | Browse the PostgreSQL database tables (requires DB) |
| ğŸ“Š Statistics | Component counts and job history charts (requires DB) |
| â„¹ï¸ About | Version and environment info |

---

## Running from the command line

```bash
# Process a single image
python src/pipeline.py \
  --model runs/detect/component_detector/weights/best.pt \
  --image path/to/board.jpg

# Process a whole directory
python src/pipeline.py \
  --model runs/detect/component_detector/weights/best.pt \
  --image-dir path/to/images/

# With database logging
python src/pipeline.py \
  --model runs/detect/component_detector/weights/best.pt \
  --image path/to/board.jpg \
  --use-database
```

---

## Optional: PostgreSQL database

The database is entirely optional. Without it, all results are still saved to the `jobs/` folder.

```bash
# Start the database container
docker-compose up -d

# Copy and edit the environment file
cp .env.example .env   # adjust credentials if needed
```

The `.env` variables used:

| Variable | Default |
|----------|---------|
| `DB_HOST` | `localhost` |
| `DB_PORT` | `5432` |
| `DB_NAME` | `nuts_vision` |
| `DB_USER` | `nuts_user` |
| `DB_PASSWORD` | `nuts_password` |

---

## YOLO model

The detection model is a **YOLOv8** model trained on the **CompDetect v3** dataset (583 annotated PCB images, 16 classes, CC BY 4.0).

See **[YOLO_MODEL.md](YOLO_MODEL.md)** for full details on:
- where the model file is located in the project
- how to train a new model from scratch
- how to swap in a custom or pre-trained model

---

## Dataset

**CompDetect v3** â€” sourced from Roboflow  
Workspace: `peanuts-q9amc` Â· Project: `compdetect-f6vw8` Â· Version 3  
License: CC BY 4.0  
See `README.roboflow.txt` and `data.yaml` for full details.

---

## License

CC BY 4.0 â€” same terms as the CompDetect dataset.